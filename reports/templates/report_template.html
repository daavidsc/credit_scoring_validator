<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Bias & Fairness Report</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 40px;
            background: #f8f9fa;
            line-height: 1.6;
        }

        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }

        h2 {
            color: #3498db;
            margin-top: 40px;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }

        h3 {
            color: #34495e;
            margin-top: 25px;
        }

        .summary-box {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin: 20px 0;
        }

        .bias-level {
            display: inline-block;
            padding: 5px 12px;
            border-radius: 20px;
            color: white;
            font-weight: bold;
            margin-left: 10px;
        }

        .bias-high { background-color: #e74c3c; }
        .bias-low { background-color: #f39c12; }
        .bias-minimal { background-color: #27ae60; }

        table {
            border-collapse: collapse;
            width: 100%;
            margin-top: 10px;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        th,
        td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ecf0f1;
        }

        th {
            background: #3498db;
            color: white;
            font-weight: 600;
        }

        tr:hover {
            background: #f8f9fa;
        }

        .metric-card {
            background: white;
            padding: 15px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin: 10px 0;
            display: inline-block;
            min-width: 200px;
            margin-right: 20px;
        }

        .metric-value {
            font-size: 2em;
            font-weight: bold;
            color: #3498db;
        }

        .quality-excellent {
            color: #27ae60 !important;
        }

        .quality-good {
            color: #f39c12 !important;
        }

        .quality-fair {
            color: #e67e22 !important;
        }

        .quality-poor {
            color: #e74c3c !important;
        }

        .metric-label {
            color: #7f8c8d;
            font-size: 0.9em;
        }

        .explanation {
            background: #ecf0f1;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 4px solid #3498db;
        }

        .warning {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }

        .alert {
            background: #f8d7da;
            border-left: 4px solid #dc3545;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
    </style>
</head>

<body>

    <h1>üìä Enhanced Bias & Fairness Analysis Report</h1>
    
    <div class="summary-box">
        <h3>üìã Executive Summary</h3>
        <p>This report analyzes potential bias in credit scoring decisions across protected attributes using two complementary approaches:</p>
        <ul>
            <li><strong>Observational Analysis:</strong> Compares overall outcomes across demographic groups</li>
            <li><strong>Counterfactual Analysis:</strong> Tests for disparate treatment by changing only protected attributes</li>
            <li><strong>Data Quality Analysis:</strong> Evaluates API response reliability and error rates</li>
        </ul>
    </div>

    {% if results.data_quality %}
    <h2>üîß Data Quality & System Reliability</h2>
    
    <div class="summary-box">
        <div class="metric-card">
            <div class="metric-value quality-{{ results.data_quality.overall_quality.level|lower }}">{{ "%.1f"|format(results.data_quality.overall_quality.score) }}%</div>
            <div class="metric-label">Overall Data Quality Score</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value">{{ "%.1f"|format(results.data_quality.error_metrics.error_rate) }}%</div>
            <div class="metric-label">Error Rate</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value">{{ results.data_quality.error_metrics.total_requests }}</div>
            <div class="metric-label">Total Requests</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value">{{ results.data_quality.error_metrics.valid_scores }}</div>
            <div class="metric-label">Valid Scores Received</div>
        </div>

        {% set quality_level = results.data_quality.overall_quality.level %}
        {% if quality_level == "Poor" %}
        <div class="alert">
            ‚ö†Ô∏è <strong>Poor Data Quality Detected:</strong> System reliability issues may impact bias analysis accuracy.
        </div>
        {% elif quality_level == "Fair" %}
        <div class="warning">
            ‚ö†Ô∏è <strong>Fair Data Quality:</strong> Some system reliability concerns noted.
        </div>
        {% endif %}

        {% if results.data_quality.error_metrics.error_breakdown %}
        <h4>Error Breakdown</h4>
        <table>
            <tr>
                <th>Error Type</th>
                <th>Count</th>
                <th>Percentage</th>
                <th>Description</th>
            </tr>
            {% for error_type, error_data in results.data_quality.error_metrics.error_breakdown.items() %}
            <tr>
                <td><strong>{{ error_type|replace("_", " ")|title }}</strong></td>
                <td>{{ error_data.count }}</td>
                <td>{{ "%.1f"|format(error_data.percentage) }}%</td>
                <td>
                    {% if error_type == "http_error" %}HTTP/API errors (500, 401, etc.)
                    {% elif error_type == "timeout" %}Request timeouts
                    {% elif error_type == "connection_error" %}Network connectivity issues
                    {% elif error_type == "missing_score" %}API responded but no credit score provided
                    {% elif error_type == "parsing_error" %}Response format issues
                    {% else %}{{ error_type|replace("_", " ")|title }}
                    {% endif %}
                </td>
            </tr>
            {% endfor %}
        </table>
        {% endif %}

        <h4>Response Completeness Analysis</h4>
        <div class="metric-card">
            <div class="metric-value">{{ "%.1f"|format(results.data_quality.completeness_metrics.completeness_score) }}%</div>
            <div class="metric-label">Response Completeness Score</div>
        </div>
        
        {% if results.data_quality.completeness_metrics.issues %}
        <table>
            <tr>
                <th>Completeness Issue</th>
                <th>Count</th>
                <th>Percentage</th>
            </tr>
            {% for issue_type, issue_data in results.data_quality.completeness_metrics.issues.items() %}
            <tr>
                <td><strong>{{ issue_type|replace("_", " ")|title }}</strong></td>
                <td>{{ issue_data.count }}</td>
                <td>{{ "%.1f"|format(issue_data.percentage) }}%</td>
            </tr>
            {% endfor %}
        </table>
        {% endif %}

        <h4>üìã Recommendations</h4>
        <ul>
            {% for recommendation in results.data_quality.recommendations %}
            <li>{{ recommendation }}</li>
            {% endfor %}
        </ul>
    </div>
    {% endif %}

    {% for attr, attr_results in results.items() %}
    {% if attr != "data_quality" %}
    <h2>üîç Protected Attribute: {{ attr|title }}</h2>

    <div class="summary-box">
        <h3>üìà Observational Analysis (Disparate Impact)</h3>
        
        <div class="explanation">
            <strong>What this measures:</strong> Whether different demographic groups receive different outcomes overall. 
            This could be due to legitimate differences (income, credit history) or potential bias.
        </div>

        <div class="metric-card">
            <div class="metric-value">{{ "%.2f"|format(attr_results.disparate_impact_ratio) }}</div>
            <div class="metric-label">Disparate Impact Ratio</div>
        </div>
        
        {% if attr_results.disparate_impact_ratio < 0.8 %}
        <div class="warning">
            ‚ö†Ô∏è <strong>Potential Disparate Impact:</strong> Ratio below 0.8 suggests significant differences in outcomes between groups.
        </div>
        {% endif %}

        <h4>Credit Score Classifications by Group</h4>
        <table>
            <tr>
                <th>Group</th>
                <th>Total</th>
                <th>"Good" Ratings</th>
                <th>"Good" Rate</th>
                <th>Avg Score</th>
                <th>Poor</th>
                <th>Average</th>
                <th>Good</th>
            </tr>
            {% for group, values in attr_results.demographic_parity.items() %}
            <tr>
                <td><strong>{{ group }}</strong></td>
                <td>{{ values.total }}</td>
                <td>{{ values.positive }}</td>
                <td>{{ "%.1f"|format(values.positive / values.total * 100) }}%</td>
                <td>{{ "%.1f"|format(values.scores|sum / values.scores|length) if values.scores else "N/A" }}</td>
                <td>{{ "%.1f"|format(values.classifications.Poor / values.total * 100) }}%</td>
                <td>{{ "%.1f"|format(values.classifications.Average / values.total * 100) }}%</td>
                <td>{{ "%.1f"|format(values.classifications.Good / values.total * 100) }}%</td>
            </tr>
            {% endfor %}
        </table>
    </div>

    <div class="summary-box">
        <h3>ÔøΩ Counterfactual Analysis (Disparate Treatment)</h3>
        
        <div class="explanation">
            <strong>What this measures:</strong> Whether the model treats identical people differently based solely on protected attributes. 
            This directly tests for unfair bias by keeping all other factors constant.
        </div>

        {% set cf = attr_results.counterfactual_fairness %}
        
        <div class="metric-card">
            <div class="metric-value">
                {% if cf.violation_ratio is not none %}
                {{ "%.1f"|format(cf.violation_ratio * 100) }}%
                {% else %}
                N/A
                {% endif %}
            </div>
            <div class="metric-label">Bias Violation Rate</div>
        </div>

        <div class="metric-card">
            <div class="metric-value">{{ cf.violations or "N/A" }}</div>
            <div class="metric-label">Total Violations</div>
        </div>

        <div class="metric-card">
            <div class="metric-value">{{ cf.sample_size or "N/A" }}</div>
            <div class="metric-label">Sample Size Tested</div>
        </div>

        {% if cf.bias_level %}
        <span class="bias-level bias-{{ cf.bias_level|lower }}">{{ cf.bias_level }} BIAS</span>
        {% endif %}

        {% if cf.violation_ratio is not none %}
            {% if cf.violation_ratio > 0.05 %}
            <div class="alert">
                üö® <strong>HIGH BIAS DETECTED:</strong> {{ "%.1f"|format(cf.violation_ratio * 100) }}% of identical profiles received different outcomes when only {{ attr }} was changed. This suggests potential discriminatory treatment.
            </div>
            {% elif cf.violation_ratio > 0.01 %}
            <div class="warning">
                ‚ö†Ô∏è <strong>LOW BIAS DETECTED:</strong> {{ "%.1f"|format(cf.violation_ratio * 100) }}% violation rate indicates some potential bias that should be investigated.
            </div>
            {% else %}
            <div class="explanation">
                ‚úÖ <strong>MINIMAL BIAS:</strong> Very low violation rate ({{ "%.1f"|format(cf.violation_ratio * 100) }}%) suggests the model treats people fairly regardless of {{ attr }}.
            </div>
            {% endif %}
        {% else %}
        <div class="explanation">
            ‚ÑπÔ∏è Counterfactual analysis not available - insufficient distinct values in the dataset.
        </div>
        {% endif %}

        {% if cf.total_tests %}
        <p><strong>Analysis Details:</strong></p>
        <ul>
            <li>Tested {{ cf.total_tests }} counterfactual comparisons across {{ cf.sample_size }} profiles</li>
            <li>Violations detected when score differed by ‚â•10 points or classification changed</li>
            <li>Each violation represents a case where changing only {{ attr }} affected the credit decision</li>
        </ul>
        {% endif %}
    </div>

    <div class="summary-box">
        <h3>üí° Interpretation Guide</h3>
        <ul>
            <li><strong>High Disparate Impact + High Counterfactual Violations:</strong> Strong evidence of discriminatory bias</li>
            <li><strong>High Disparate Impact + Low Counterfactual Violations:</strong> Likely due to legitimate differences in financial profiles</li>
            <li><strong>Low Disparate Impact + High Counterfactual Violations:</strong> Hidden bias that affects individuals but doesn't show in aggregate</li>
            <li><strong>Low Disparate Impact + Low Counterfactual Violations:</strong> Fair treatment across groups</li>
        </ul>
    </div>

    {% endif %}
    {% endfor %}

    <div class="summary-box">
        <h3>üéØ Recommendations</h3>
        <ul>
            <li><strong>Disparate Impact Ratio < 0.8:</strong> Review model features and consider bias mitigation techniques</li>
            <li><strong>Counterfactual Violations > 5%:</strong> Investigate model for direct discrimination and consider algorithmic auditing</li>
            <li><strong>Both metrics concerning:</strong> Immediate action required - consider model retraining with fairness constraints</li>
            <li><strong>Regular monitoring:</strong> Implement ongoing bias testing as part of model governance</li>
        </ul>
    </div>

</body>

</html>