<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Credit Scoring Bias & Fairness Analysis Report</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            padding: 40px;
        }
        
        .header {
            text-align: center;
            margin-bottom: 40px;
            padding-bottom: 20px;
            border-bottom: 3px solid #667eea;
        }
        
        .header h1 {
            color: #333;
            font-size: 2.5em;
            margin: 0 0 10px 0;
            font-weight: 700;
        }
        
        .header p {
            color: #666;
            font-size: 1.1em;
            margin: 0;
        }
        
        .summary-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }
        
        .metric-card {
            background: linear-gradient(135deg, #f8f9ff 0%, #e3f2fd 100%);
            padding: 25px;
            border-radius: 12px;
            text-align: center;
            border: 1px solid #e0e7ff;
            transition: transform 0.3s ease;
        }
        
        .metric-card:hover {
            transform: translateY(-5px);
        }
        
        .metric-value {
            font-size: 2.5em;
            font-weight: bold;
            color: #2563eb;
            margin-bottom: 5px;
        }
        
        .metric-label {
            font-size: 1em;
            color: #64748b;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        
        .section {
            background: #fafbfc;
            margin-bottom: 30px;
            padding: 30px;
            border-radius: 12px;
            border-left: 5px solid #667eea;
        }
        
        .section h2 {
            color: #1e293b;
            font-size: 1.8em;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .section h3 {
            color: #334155;
            font-size: 1.3em;
            margin-bottom: 15px;
            margin-top: 25px;
        }
        
        .bias-level {
            display: inline-block;
            padding: 8px 16px;
            border-radius: 20px;
            color: white;
            font-weight: bold;
            margin-left: 10px;
            font-size: 0.9em;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .bias-high { 
            background: linear-gradient(135deg, #dc2626 0%, #b91c1c 100%); 
            box-shadow: 0 2px 10px rgba(220, 38, 38, 0.3);
        }
        .bias-low { 
            background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%); 
            box-shadow: 0 2px 10px rgba(245, 158, 11, 0.3);
        }
        .bias-minimal { 
            background: linear-gradient(135deg, #10b981 0%, #059669 100%); 
            box-shadow: 0 2px 10px rgba(16, 185, 129, 0.3);
        }
        
        .metrics-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .metrics-table th,
        .metrics-table td {
            padding: 15px;
            text-align: left;
            border-bottom: 1px solid #e5e7eb;
        }
        
        .metrics-table th {
            background: #f8fafc;
            font-weight: 600;
            color: #374151;
            text-transform: uppercase;
            font-size: 0.9em;
            letter-spacing: 0.5px;
        }
        
        .metrics-table tr:hover {
            background: #f8fafc;
        }
        
        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
        }
        
        .status-good { background: #10b981; }
        .status-warning { background: #f59e0b; }
        .status-poor { background: #ef4444; }
        
        .good { color: #059669; font-weight: bold; }
        .warning { color: #d97706; font-weight: bold; }
        .poor { color: #dc2626; font-weight: bold; }
        
        .data-quality-summary {
            background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%);
            padding: 20px;
            border-radius: 10px;
            border: 1px solid #f59e0b;
            margin: 20px 0;
        }
        
        .data-quality-good {
            background: linear-gradient(135deg, #dcfce7 0%, #bbf7d0 100%);
            border-color: #10b981;
        }
        
        .data-quality-poor {
            background: linear-gradient(135deg, #fef2f2 0%, #fecaca 100%);
            border-color: #ef4444;
        }
        
        .attribute-analysis {
            background: white;
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
            border: 1px solid #e5e7eb;
            transition: box-shadow 0.3s ease;
        }
        
        .attribute-analysis:hover {
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        
        .demographic-parity-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        
        .parity-card {
            background: #f8fafc;
            padding: 15px;
            border-radius: 8px;
            border: 1px solid #e5e7eb;
            text-align: center;
        }
        
        .parity-group {
            font-weight: 600;
            color: #374151;
            margin-bottom: 10px;
        }
        
        .parity-rate {
            font-size: 1.5em;
            font-weight: bold;
            color: #2563eb;
        }
        
        .parity-details {
            font-size: 0.9em;
            color: #6b7280;
            margin-top: 8px;
        }
        
        .counterfactual-result {
            background: white;
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
            margin: 10px 0;
        }
        
        .violation-high {
            border-left-color: #dc2626;
            background: #fef2f2;
        }
        
        .violation-low {
            border-left-color: #f59e0b;
            background: #fefbf2;
        }
        
        .violation-minimal {
            border-left-color: #10b981;
            background: #f0fdf4;
        }
        
        .footer {
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e5e7eb;
            color: #6b7280;
            font-size: 0.9em;
        }
        
        .timestamp {
            color: #9ca3af;
            font-size: 0.8em;
        }
        
        .warning-box {
            background: #fef3cd;
            border: 1px solid #fde68a;
            color: #92400e;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .error-box {
            background: #fef2f2;
            border: 1px solid #fecaca;
            color: #dc2626;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .success-box {
            background: #f0fdf4;
            border: 1px solid #bbf7d0;
            color: #166534;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>‚öñÔ∏è Credit Scoring Bias & Fairness Analysis</h1>
            <p>Comprehensive evaluation of fairness across protected attributes</p>
            <p class="timestamp">Generated on {{ "now" | date }}</p>
        <!-- Summary Section -->
        {% if results.data_quality %}
        <div class="section">
            <h2>üìä Data Quality Overview</h2>
            {% set quality = results.data_quality.overall_quality %}
            <div class="data-quality-summary {% if quality.score >= 80 %}data-quality-good{% elif quality.score >= 60 %}{% else %}data-quality-poor{% endif %}">
                <div class="summary-grid">
                    <div class="metric-card">
                        <div class="metric-value">{{ quality.score | round(1) }}%</div>
                        <div class="metric-label">Overall Quality</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">{{ results.data_quality.summary.total_responses }}</div>
                        <div class="metric-label">Total Responses</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">{{ results.data_quality.summary.successful_predictions }}</div>
                        <div class="metric-label">Successful Predictions</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">{{ (results.data_quality.summary.success_rate * 100) | round(1) }}%</div>
                        <div class="metric-label">Success Rate</div>
                    </div>
                </div>
                
                {% if quality.score < 60 %}
                <div class="error-box">
                    <strong>‚ö†Ô∏è Poor Data Quality Detected:</strong> System reliability issues may impact bias analysis accuracy.
                </div>
                {% elif quality.score < 80 %}
                <div class="warning-box">
                    <strong>‚ö†Ô∏è Moderate Data Quality:</strong> Some data quality issues detected. Results should be interpreted with caution.
                </div>
                {% else %}
                <div class="success-box">
                    <strong>‚úÖ Good Data Quality:</strong> Analysis results are reliable with high-quality data.
                </div>
                {% endif %}
            </div>
        </div>
        {% endif %}

        .metric-value {
            font-size: 2em;
            font-weight: bold;
            color: #3498db;
        }

        .quality-excellent {
            color: #27ae60 !important;
        }

        .quality-good {
            color: #f39c12 !important;
        }

        .quality-fair {
            color: #e67e22 !important;
        }

        .quality-poor {
            color: #e74c3c !important;
        }

        .metric-label {
            color: #7f8c8d;
            font-size: 0.9em;
        }

        .explanation {
            background: #ecf0f1;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 4px solid #3498db;
        }

        .warning {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }

        .alert {
            background: #f8d7da;
            border-left: 4px solid #dc3545;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
    </style>
</head>

<body>

    <h1>üìä Enhanced Bias & Fairness Analysis Report</h1>
    
    <div class="summary-box">
        <h3>üìã Executive Summary</h3>
        <p>This report analyzes potential bias in credit scoring decisions across protected attributes using two complementary approaches:</p>
        <ul>
            <li><strong>Observational Analysis:</strong> Compares overall outcomes across demographic groups</li>
            <li><strong>Counterfactual Analysis:</strong> Tests for disparate treatment by changing only protected attributes</li>
            <li><strong>Data Quality Analysis:</strong> Evaluates API response reliability and error rates</li>
        </ul>
    </div>

    {% if results.data_quality %}
    <h2>üîß Data Quality & System Reliability</h2>
    
    <div class="summary-box">
        <div class="metric-card">
            <div class="metric-value quality-{{ results.data_quality.overall_quality.level|lower }}">{{ "%.1f"|format(results.data_quality.overall_quality.score) }}%</div>
            <div class="metric-label">Overall Data Quality Score</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value">{{ "%.1f"|format(results.data_quality.error_metrics.error_rate) }}%</div>
            <div class="metric-label">Error Rate</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value">{{ results.data_quality.error_metrics.total_requests }}</div>
            <div class="metric-label">Total Requests</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value">{{ results.data_quality.error_metrics.valid_scores }}</div>
            <div class="metric-label">Valid Scores Received</div>
        </div>

        {% set quality_level = results.data_quality.overall_quality.level %}
        {% if quality_level == "Poor" %}
        <div class="alert">
            ‚ö†Ô∏è <strong>Poor Data Quality Detected:</strong> System reliability issues may impact bias analysis accuracy.
        </div>
        {% elif quality_level == "Fair" %}
        <div class="warning">
            ‚ö†Ô∏è <strong>Fair Data Quality:</strong> Some system reliability concerns noted.
        </div>
        {% endif %}

        {% if results.data_quality.error_metrics.error_breakdown %}
        <h4>Error Breakdown</h4>
        <table>
            <tr>
                <th>Error Type</th>
                <th>Count</th>
                <th>Percentage</th>
                <th>Description</th>
            </tr>
            {% for error_type, error_data in results.data_quality.error_metrics.error_breakdown.items() %}
            <tr>
                <td><strong>{{ error_type|replace("_", " ")|title }}</strong></td>
                <td>{{ error_data.count }}</td>
                <td>{{ "%.1f"|format(error_data.percentage) }}%</td>
                <td>
                    {% if error_type == "http_error" %}HTTP/API errors (500, 401, etc.)
                    {% elif error_type == "timeout" %}Request timeouts
                    {% elif error_type == "connection_error" %}Network connectivity issues
                    {% elif error_type == "missing_score" %}API responded but no credit score provided
                    {% elif error_type == "parsing_error" %}Response format issues
                    {% else %}{{ error_type|replace("_", " ")|title }}
                    {% endif %}
                </td>
            </tr>
            {% endfor %}
        </table>
        {% endif %}

        <h4>Response Completeness Analysis</h4>
        <div class="metric-card">
            <div class="metric-value">{{ "%.1f"|format(results.data_quality.completeness_metrics.completeness_score) }}%</div>
            <div class="metric-label">Response Completeness Score</div>
        </div>
        
        {% if results.data_quality.completeness_metrics.issues %}
        <table>
            <tr>
                <th>Completeness Issue</th>
                <th>Count</th>
                <th>Percentage</th>
            </tr>
            {% for issue_type, issue_data in results.data_quality.completeness_metrics.issues.items() %}
            <tr>
                <td><strong>{{ issue_type|replace("_", " ")|title }}</strong></td>
                <td>{{ issue_data.count }}</td>
                <td>{{ "%.1f"|format(issue_data.percentage) }}%</td>
            </tr>
            {% endfor %}
        </table>
        {% endif %}

        <h4>üìã Recommendations</h4>
        <ul>
            {% for recommendation in results.data_quality.recommendations %}
            <li>{{ recommendation }}</li>
            {% endfor %}
        </ul>
    </div>
    {% endif %}

    {% for attr, attr_results in results.items() %}
    {% if attr != "data_quality" %}
    <h2>üîç Protected Attribute: {{ attr|title }}</h2>

    <div class="summary-box">
        <h3>üìà Observational Analysis (Disparate Impact)</h3>
        
        <div class="explanation">
            <strong>What this measures:</strong> Whether different demographic groups receive different outcomes overall. 
            This could be due to legitimate differences (income, credit history) or potential bias.
        </div>

        <div class="metric-card">
            <div class="metric-value">{{ "%.2f"|format(attr_results.disparate_impact_ratio) }}</div>
            <div class="metric-label">Disparate Impact Ratio</div>
        </div>
        
        {% if attr_results.disparate_impact_ratio < 0.8 %}
        <div class="warning">
            ‚ö†Ô∏è <strong>Potential Disparate Impact:</strong> Ratio below 0.8 suggests significant differences in outcomes between groups.
        </div>
        {% endif %}

        <h4>Credit Score Classifications by Group</h4>
        <table>
            <tr>
                <th>Group</th>
                <th>Total</th>
                <th>"Good" Ratings</th>
                <th>"Good" Rate</th>
                <th>Avg Score</th>
                <th>Poor</th>
                <th>Average</th>
                <th>Good</th>
            </tr>
            {% for group, values in attr_results.demographic_parity.items() %}
            <tr>
                <td><strong>{{ group }}</strong></td>
                <td>{{ values.total }}</td>
                <td>{{ values.positive }}</td>
                <td>{{ "%.1f"|format(values.positive / values.total * 100) }}%</td>
                <td>{{ "%.1f"|format(values.scores|sum / values.scores|length) if values.scores else "N/A" }}</td>
                <td>{{ "%.1f"|format(values.classifications.Poor / values.total * 100) }}%</td>
                <td>{{ "%.1f"|format(values.classifications.Average / values.total * 100) }}%</td>
                <td>{{ "%.1f"|format(values.classifications.Good / values.total * 100) }}%</td>
            </tr>
            {% endfor %}
        </table>
    </div>

    <div class="summary-box">
        <h3>ÔøΩ Counterfactual Analysis (Disparate Treatment)</h3>
        
        <div class="explanation">
            <strong>What this measures:</strong> Whether the model treats identical people differently based solely on protected attributes. 
            This directly tests for unfair bias by keeping all other factors constant.
        </div>

        {% set cf = attr_results.counterfactual_fairness %}
        
        <div class="metric-card">
            <div class="metric-value">
                {% if cf.violation_ratio is not none %}
                {{ "%.1f"|format(cf.violation_ratio * 100) }}%
                {% else %}
                N/A
                {% endif %}
            </div>
            <div class="metric-label">Bias Violation Rate</div>
        </div>

        <div class="metric-card">
            <div class="metric-value">{{ cf.violations or "N/A" }}</div>
            <div class="metric-label">Total Violations</div>
        </div>

        <div class="metric-card">
            <div class="metric-value">{{ cf.sample_size or "N/A" }}</div>
            <div class="metric-label">Sample Size Tested</div>
        </div>

        {% if cf.bias_level %}
        <span class="bias-level bias-{{ cf.bias_level|lower }}">{{ cf.bias_level }} BIAS</span>
        {% endif %}

        {% if cf.violation_ratio is not none %}
            {% if cf.violation_ratio > 0.05 %}
            <div class="alert">
                üö® <strong>HIGH BIAS DETECTED:</strong> {{ "%.1f"|format(cf.violation_ratio * 100) }}% of identical profiles received different outcomes when only {{ attr }} was changed. This suggests potential discriminatory treatment.
            </div>
            {% elif cf.violation_ratio > 0.01 %}
            <div class="warning">
                ‚ö†Ô∏è <strong>LOW BIAS DETECTED:</strong> {{ "%.1f"|format(cf.violation_ratio * 100) }}% violation rate indicates some potential bias that should be investigated.
            </div>
            {% else %}
            <div class="explanation">
                ‚úÖ <strong>MINIMAL BIAS:</strong> Very low violation rate ({{ "%.1f"|format(cf.violation_ratio * 100) }}%) suggests the model treats people fairly regardless of {{ attr }}.
            </div>
            {% endif %}
        {% else %}
        <div class="explanation">
            ‚ÑπÔ∏è Counterfactual analysis not available - insufficient distinct values in the dataset.
        </div>
        {% endif %}

        {% if cf.total_tests %}
        <p><strong>Analysis Details:</strong></p>
        <ul>
            <li>Tested {{ cf.total_tests }} counterfactual comparisons across {{ cf.sample_size }} profiles</li>
            <li>Violations detected when score differed by ‚â•10 points or classification changed</li>
            <li>Each violation represents a case where changing only {{ attr }} affected the credit decision</li>
        </ul>
        {% endif %}
    </div>

    <div class="summary-box">
        <h3>üí° Interpretation Guide</h3>
        <ul>
            <li><strong>High Disparate Impact + High Counterfactual Violations:</strong> Strong evidence of discriminatory bias</li>
            <li><strong>High Disparate Impact + Low Counterfactual Violations:</strong> Likely due to legitimate differences in financial profiles</li>
            <li><strong>Low Disparate Impact + High Counterfactual Violations:</strong> Hidden bias that affects individuals but doesn't show in aggregate</li>
            <li><strong>Low Disparate Impact + Low Counterfactual Violations:</strong> Fair treatment across groups</li>
        </ul>
    </div>

    {% endif %}
    {% endfor %}

    <div class="summary-box">
        <h3>üéØ Recommendations</h3>
        <ul>
            <li><strong>Disparate Impact Ratio < 0.8:</strong> Review model features and consider bias mitigation techniques</li>
            <li><strong>Counterfactual Violations > 5%:</strong> Investigate model for direct discrimination and consider algorithmic auditing</li>
            <li><strong>Both metrics concerning:</strong> Immediate action required - consider model retraining with fairness constraints</li>
            <li><strong>Regular monitoring:</strong> Implement ongoing bias testing as part of model governance</li>
        </ul>
    </div>

</body>

</html>