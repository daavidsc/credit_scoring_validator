<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Credit Scoring Bias & Fairness Analysis Report</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            padding: 40px;
        }
        
        .header {
            text-align: center;
            margin-bottom: 40px;
            padding-bottom: 20px;
            border-bottom: 3px solid #667eea;
        }
        
        .header h1 {
            color: #333;
            font-size: 2.5em;
            margin: 0 0 10px 0;
            font-weight: 700;
        }
        
        .header p {
            color: #666;
            font-size: 1.1em;
            margin: 0;
        }
        
        .summary-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }
        
        .metric-card {
            background: linear-gradient(135deg, #f8f9ff 0%, #e3f2fd 100%);
            padding: 25px;
            border-radius: 12px;
            text-align: center;
            border: 1px solid #e0e7ff;
            transition: transform 0.3s ease;
        }
        
        .metric-card:hover {
            transform: translateY(-5px);
        }
        
        .metric-value {
            font-size: 2.5em;
            font-weight: bold;
            color: #2563eb;
            margin-bottom: 5px;
        }
        
        .metric-label {
            font-size: 1em;
            color: #64748b;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        
        .section {
            background: #fafbfc;
            margin-bottom: 30px;
            padding: 30px;
            border-radius: 12px;
            border-left: 5px solid #667eea;
        }
        
        .section h2 {
            color: #1e293b;
            font-size: 1.8em;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .section h3 {
            color: #334155;
            font-size: 1.3em;
            margin-bottom: 15px;
            margin-top: 25px;
        }
        
        .bias-level {
            display: inline-block;
            padding: 8px 16px;
            border-radius: 20px;
            color: white;
            font-weight: bold;
            margin-left: 10px;
            font-size: 0.9em;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .bias-high { 
            background: linear-gradient(135deg, #dc2626 0%, #b91c1c 100%); 
            box-shadow: 0 2px 10px rgba(220, 38, 38, 0.3);
        }
        .bias-low { 
            background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%); 
            box-shadow: 0 2px 10px rgba(245, 158, 11, 0.3);
        }
        .bias-minimal { 
            background: linear-gradient(135deg, #10b981 0%, #059669 100%); 
            box-shadow: 0 2px 10px rgba(16, 185, 129, 0.3);
        }
        
        .metrics-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .metrics-table th,
        .metrics-table td {
            padding: 15px;
            text-align: left;
            border-bottom: 1px solid #e5e7eb;
        }
        
        .metrics-table th {
            background: #f8fafc;
            font-weight: 600;
            color: #374151;
            text-transform: uppercase;
            font-size: 0.9em;
            letter-spacing: 0.5px;
        }
        
        .metrics-table tr:hover {
            background: #f8fafc;
        }
        
        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
        }
        
        .status-good { background: #10b981; }
        .status-warning { background: #f59e0b; }
        .status-poor { background: #ef4444; }
        
        .good { color: #059669; font-weight: bold; }
        .warning { color: #d97706; font-weight: bold; }
        .poor { color: #dc2626; font-weight: bold; }
        
        .data-quality-summary {
            background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%);
            padding: 20px;
            border-radius: 10px;
            border: 1px solid #f59e0b;
            margin: 20px 0;
        }
        
        .data-quality-good {
            background: linear-gradient(135deg, #dcfce7 0%, #bbf7d0 100%);
            border-color: #10b981;
        }
        
        .data-quality-poor {
            background: linear-gradient(135deg, #fef2f2 0%, #fecaca 100%);
            border-color: #ef4444;
        }
        
        .attribute-analysis {
            background: white;
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
            border: 1px solid #e5e7eb;
            transition: box-shadow 0.3s ease;
        }
        
        .attribute-analysis:hover {
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        
        .demographic-parity-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        
        .parity-card {
            background: #f8fafc;
            padding: 15px;
            border-radius: 8px;
            border: 1px solid #e5e7eb;
            text-align: center;
        }
        
        .parity-group {
            font-weight: 600;
            color: #374151;
            margin-bottom: 10px;
        }
        
        .parity-rate {
            font-size: 1.5em;
            font-weight: bold;
            color: #2563eb;
        }
        
        .parity-details {
            font-size: 0.9em;
            color: #6b7280;
            margin-top: 8px;
        }
        
        .counterfactual-result {
            background: white;
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
            margin: 10px 0;
        }
        
        .violation-high {
            border-left-color: #dc2626;
            background: #fef2f2;
        }
        
        .violation-low {
            border-left-color: #f59e0b;
            background: #fefbf2;
        }
        
        .violation-minimal {
            border-left-color: #10b981;
            background: #f0fdf4;
        }
        
        .footer {
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e5e7eb;
            color: #6b7280;
            font-size: 0.9em;
        }
        
        .timestamp {
            color: #9ca3af;
            font-size: 0.8em;
        }
        
        .warning-box {
            background: #fef3cd;
            border: 1px solid #fde68a;
            color: #92400e;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .error-box {
            background: #fef2f2;
            border: 1px solid #fecaca;
            color: #dc2626;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .success-box {
            background: #f0fdf4;
            border: 1px solid #bbf7d0;
            color: #166534;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .executive-summary {
            background: linear-gradient(135deg, #f1f5f9 0%, #e2e8f0 100%);
            padding: 25px;
            border-radius: 10px;
            margin-bottom: 30px;
            border: 1px solid #cbd5e1;
        }
        
        .executive-summary h3 {
            color: #1e293b;
            margin-top: 0;
        }
        
        .executive-summary ul {
            margin: 15px 0;
            padding-left: 20px;
        }
        
        .executive-summary li {
            margin-bottom: 8px;
            color: #475569;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>‚öñÔ∏è Credit Scoring Bias & Fairness Analysis</h1>
            <p>Comprehensive evaluation of fairness across protected attributes</p>
            <p class="timestamp">Generated on {{ "now" | date }}</p>
        </div>

        <!-- Executive Summary -->
        <div class="executive-summary">
            <h3>üìã Executive Summary</h3>
            <p>This report analyzes potential bias in credit scoring decisions across protected attributes using two complementary approaches:</p>
            <ul>
                <li><strong>Observational Analysis:</strong> Compares overall outcomes across demographic groups</li>
                <li><strong>Counterfactual Analysis:</strong> Tests for disparate treatment by changing only protected attributes</li>
                <li><strong>Data Quality Analysis:</strong> Evaluates API response reliability and error rates</li>
            </ul>
        </div>

        <!-- Data Quality Summary -->
        {% if results.data_quality %}
        <div class="section">
            <h2>üìä Data Quality Overview</h2>
            {% set quality = results.data_quality.overall_quality %}
            <div class="data-quality-summary {% if quality.score >= 80 %}data-quality-good{% elif quality.score >= 60 %}{% else %}data-quality-poor{% endif %}">
                <div class="summary-grid">
                    <div class="metric-card">
                        <div class="metric-value">{{ quality.score | round(1) }}%</div>
                        <div class="metric-label">Overall Quality</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">{{ results.data_quality.summary.total_responses }}</div>
                        <div class="metric-label">Total Responses</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">{{ results.data_quality.summary.successful_predictions }}</div>
                        <div class="metric-label">Successful Predictions</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">{{ (results.data_quality.summary.success_rate * 100) | round(1) }}%</div>
                        <div class="metric-label">Success Rate</div>
                    </div>
                </div>
                
                {% if quality.score < 60 %}
                <div class="error-box">
                    <strong>‚ö†Ô∏è Poor Data Quality Detected:</strong> System reliability issues may impact bias analysis accuracy.
                </div>
                {% elif quality.score < 80 %}
                <div class="warning-box">
                    <strong>‚ö†Ô∏è Moderate Data Quality:</strong> Some data quality issues detected. Results should be interpreted with caution.
                </div>
                {% else %}
                <div class="success-box">
                    <strong>‚úÖ Good Data Quality:</strong> Analysis results are reliable with high-quality data.
                </div>
                {% endif %}

                <h3>Error Breakdown</h3>
                <table class="metrics-table">
                    <thead>
                        <tr>
                            <th>Error Type</th>
                            <th>Count</th>
                            <th>Percentage</th>
                            <th>Impact</th>
                        </tr>
                    </thead>
                    <tbody>
                        {% for error_type, count in results.data_quality.error_breakdown.items() %}
                        <tr>
                            <td>{{ error_type | title }}</td>
                            <td>{{ count }}</td>
                            <td>{{ (count / results.data_quality.summary.total_responses * 100) | round(1) }}%</td>
                            <td>
                                {% set error_rate = count / results.data_quality.summary.total_responses %}
                                {% if error_rate <= 0.05 %}
                                <span class="status-indicator status-good"></span><span class="good">Low</span>
                                {% elif error_rate <= 0.15 %}
                                <span class="status-indicator status-warning"></span><span class="warning">Moderate</span>
                                {% else %}
                                <span class="status-indicator status-poor"></span><span class="poor">High</span>
                                {% endif %}
                            </td>
                        </tr>
                        {% endfor %}
                    </tbody>
                </table>
            </div>
        </div>
        {% endif %}

        <!-- Bias Analysis for Each Protected Attribute -->
        {% for attribute, analysis in results.items() %}
        {% if attribute != 'data_quality' %}
        <div class="section">
            <h2>üë• {{ attribute | title }} Analysis</h2>
            
            <div class="attribute-analysis">
                <h3>Demographic Parity</h3>
                <p>Compares the rate of positive outcomes (e.g., "Good" credit classification) across different groups within <strong>{{ attribute }}</strong>:</p>
                
                <div class="demographic-parity-grid">
                    {% for group, stats in analysis.demographic_parity.items() %}
                    <div class="parity-card">
                        <div class="parity-group">{{ group | title }}</div>
                        <div class="parity-rate">{{ ((stats.positive / stats.total * 100) if stats.total > 0 else 0) | round(1) }}%</div>
                        <div class="parity-details">
                            {{ stats.positive }}/{{ stats.total }} positive outcomes
                        </div>
                    </div>
                    {% endfor %}
                </div>
                
                <table class="metrics-table">
                    <thead>
                        <tr>
                            <th>Group</th>
                            <th>Total Cases</th>
                            <th>Positive Outcomes</th>
                            <th>Rate</th>
                            <th>Classification Distribution</th>
                        </tr>
                    </thead>
                    <tbody>
                        {% for group, stats in analysis.demographic_parity.items() %}
                        <tr>
                            <td><strong>{{ group | title }}</strong></td>
                            <td>{{ stats.total }}</td>
                            <td>{{ stats.positive }}</td>
                            <td>{{ ((stats.positive / stats.total * 100) if stats.total > 0 else 0) | round(1) }}%</td>
                            <td>
                                <small>
                                    Good: {{ stats.classifications.Good }}, 
                                    Average: {{ stats.classifications.Average }}, 
                                    Poor: {{ stats.classifications.Poor }}
                                    {% if stats.errors > 0 %}<br/>Errors: {{ stats.errors }}{% endif %}
                                </small>
                            </td>
                        </tr>
                        {% endfor %}
                    </tbody>
                </table>
                
                <div style="margin-top: 20px;">
                    <h4>Disparate Impact Ratio</h4>
                    <div class="metric-card" style="display: inline-block; margin: 10px 0;">
                        <div class="metric-value">{{ (analysis.disparate_impact_ratio * 100) | round(1) }}%</div>
                        <div class="metric-label">
                            {% if analysis.disparate_impact_ratio >= 0.8 %}
                            <span class="good">Acceptable (‚â•80%)</span>
                            {% else %}
                            <span class="poor">Concerning (&lt;80%)</span>
                            {% endif %}
                        </div>
                    </div>
                    
                    {% if analysis.disparate_impact_ratio < 0.8 %}
                    <div class="error-box">
                        <strong>‚ö†Ô∏è Disparate Impact Detected:</strong> The ratio is {{ (analysis.disparate_impact_ratio * 100) | round(1) }}%, which is below the 80% threshold commonly used to identify potential disparate impact.
                    </div>
                    {% else %}
                    <div class="success-box">
                        <strong>‚úÖ Acceptable Disparate Impact Ratio:</strong> The ratio is {{ (analysis.disparate_impact_ratio * 100) | round(1) }}%, which meets the 80% threshold.
                    </div>
                    {% endif %}
                    
                    <p style="margin-top: 10px; font-size: 0.9em; color: #6b7280;">
                        The disparate impact ratio compares the lowest group rate to the highest group rate. 
                        Values below 80% may indicate potential bias according to the "80% rule" used in fair lending practices.
                    </p>
                </div>
                
                {% if analysis.counterfactual_fairness %}
                <div class="counterfactual-result {% if analysis.counterfactual_fairness.bias_level == 'HIGH' %}violation-high{% elif analysis.counterfactual_fairness.bias_level == 'LOW' %}violation-low{% else %}violation-minimal{% endif %}">
                    <h4>Counterfactual Fairness Test</h4>
                    <p>Tests whether changing <strong>only</strong> the {{ attribute }} attribute (while keeping all other factors constant) leads to different credit decisions:</p>
                    
                    {% if analysis.counterfactual_fairness.violation_ratio %}
                    <div style="margin: 15px 0;">
                        <p><strong>Bias Level:</strong> 
                            <span class="bias-level bias-{{ analysis.counterfactual_fairness.bias_level | lower }}">
                                {{ analysis.counterfactual_fairness.bias_level }}
                            </span>
                        </p>
                        <p><strong>Violation Rate:</strong> {{ (analysis.counterfactual_fairness.violation_ratio * 100) | round(2) }}%</p>
                        <p><strong>Sample Size:</strong> {{ analysis.counterfactual_fairness.sample_size }} profiles tested</p>
                        <p><strong>Total Tests:</strong> {{ analysis.counterfactual_fairness.total_tests }} counterfactual comparisons</p>
                    </div>
                    
                    {% if analysis.counterfactual_fairness.violation_ratio > 0.05 %}
                    <div class="error-box">
                        <strong>üö® High Bias Risk:</strong> {{ (analysis.counterfactual_fairness.violation_ratio * 100) | round(2) }}% of counterfactual tests show different outcomes based on {{ attribute }}. This suggests potential disparate treatment.
                    </div>
                    {% elif analysis.counterfactual_fairness.violation_ratio > 0.01 %}
                    <div class="warning-box">
                        <strong>‚ö†Ô∏è Moderate Bias Risk:</strong> Some evidence of disparate treatment detected in {{ (analysis.counterfactual_fairness.violation_ratio * 100) | round(2) }}% of tests.
                    </div>
                    {% else %}
                    <div class="success-box">
                        <strong>‚úÖ Low Bias Risk:</strong> Minimal evidence of disparate treatment based on {{ attribute }} ({{ (analysis.counterfactual_fairness.violation_ratio * 100) | round(2) }}% violation rate).
                    </div>
                    {% endif %}
                    
                    <div style="background: #f8fafc; padding: 15px; border-radius: 8px; margin-top: 15px; border: 1px solid #e2e8f0;">
                        <strong>What is Counterfactual Fairness?</strong><br>
                        <small style="color: #64748b;">
                            This test creates "what if" scenarios by changing only the protected attribute (e.g., gender from "female" to "male") while keeping all other information identical. If the credit decision changes, it suggests the model may be making decisions based on the protected attribute, which could indicate bias.
                        </small>
                    </div>
                    {% else %}
                    <p>{{ analysis.counterfactual_fairness.note }}</p>
                    {% endif %}
                </div>
                {% endif %}
            </div>
        </div>
        {% endif %}
        {% endfor %}
        
        <div class="footer">
            <p>Credit Scoring Validator - Bias & Fairness Analysis Report</p>
            <p>This report uses both observational and counterfactual methods to detect potential bias in credit scoring decisions across protected demographic attributes.</p>
        </div>
    </div>
</body>
</html>
