<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Credit Scoring Accuracy Analysis Report</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            padding: 40px;
        }
        
        .header {
            text-align: center;
            margin-bottom: 40px;
            padding-bottom: 20px;
            border-bottom: 3px solid #667eea;
        }
        
        .header h1 {
            color: #333;
            font-size: 2.5em;
            margin: 0 0 10px 0;
            font-weight: 700;
        }
        
        .header p {
            color: #666;
            font-size: 1.1em;
            margin: 0;
        }
        
        .summary-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }
        
        .metric-card {
            background: linear-gradient(135deg, #f8f9ff 0%, #e3f2fd 100%);
            padding: 25px;
            border-radius: 12px;
            text-align: center;
            border: 1px solid #e0e7ff;
            transition: transform 0.3s ease;
        }
        
        .metric-card:hover {
            transform: translateY(-5px);
        }
        
        .metric-value {
            font-size: 2.5em;
            font-weight: bold;
            color: #2563eb;
            margin-bottom: 5px;
        }
        
        .metric-label {
            font-size: 1em;
            color: #64748b;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        
        .section {
            background: #fafbfc;
            margin-bottom: 30px;
            padding: 30px;
            border-radius: 12px;
            border-left: 5px solid #667eea;
        }
        
        .section h2 {
            color: #1e293b;
            font-size: 1.8em;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .section h3 {
            color: #334155;
            font-size: 1.3em;
            margin-bottom: 15px;
            margin-top: 25px;
        }
        
        .metrics-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .metrics-table th,
        .metrics-table td {
            padding: 15px;
            text-align: left;
            border-bottom: 1px solid #e5e7eb;
        }
        
        .metrics-table th {
            background: #f8fafc;
            font-weight: 600;
            color: #374151;
            text-transform: uppercase;
            font-size: 0.9em;
            letter-spacing: 0.5px;
        }
        
        .metrics-table tr:hover {
            background: #f8fafc;
        }
        
        .good { color: #059669; font-weight: bold; }
        .warning { color: #d97706; font-weight: bold; }
        .poor { color: #dc2626; font-weight: bold; }
        
        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
        }
        
        .status-good { background: #10b981; }
        .status-warning { background: #f59e0b; }
        .status-poor { background: #ef4444; }
        
        .distribution-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        
        .distribution-card {
            background: white;
            padding: 20px;
            border-radius: 8px;
            border: 1px solid #e5e7eb;
            text-align: center;
        }
        
        .range-label {
            font-weight: 600;
            color: #374151;
            margin-bottom: 10px;
        }
        
        .range-values {
            display: flex;
            justify-content: space-between;
            margin-top: 10px;
        }
        
        .range-value {
            font-size: 0.9em;
            color: #6b7280;
        }
        
        .footer {
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e5e7eb;
            color: #6b7280;
            font-size: 0.9em;
        }
        
        .timestamp {
            color: #9ca3af;
            font-size: 0.8em;
        }
        
        .error-message {
            background: #fef2f2;
            border: 1px solid #fecaca;
            color: #dc2626;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéØ Credit Scoring Accuracy Analysis</h1>
            <p>Performance evaluation of credit scoring predictions</p>
            {% if results.timestamp %}
            <p class="timestamp">Generated on {{ results.timestamp }}</p>
            {% endif %}
        </div>

        {% if results.error %}
        <div class="error-message">
            <strong>Analysis Error:</strong> {{ results.error }}
        </div>
        {% else %}

        <!-- Summary Section -->
        <div class="summary-grid">
            <div class="metric-card">
                <div class="metric-value">{{ (results.summary.valid_prediction_rate * 100) | round(1) }}%</div>
                <div class="metric-label">Success Rate</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{{ results.summary.total_predictions }}</div>
                <div class="metric-label">Valid Predictions</div>
            </div>
            {% if results.regression_metrics.mae %}
            <div class="metric-card">
                <div class="metric-value">{{ results.regression_metrics.mae | round(1) }}</div>
                <div class="metric-label">Mean Abs Error</div>
            </div>
            {% endif %}
            {% if results.classification_metrics.accuracy %}
            <div class="metric-card">
                <div class="metric-value">{{ (results.classification_metrics.accuracy * 100) | round(1) }}%</div>
                <div class="metric-label">Classification Accuracy</div>
            </div>
            {% endif %}
        </div>

        {% if results.regression_metrics %}
        <!-- Regression Metrics Section -->
        <div class="section">
            <h2>üìà Regression Metrics (Credit Scores)</h2>
            <p>Performance evaluation of numerical credit score predictions (0-100 scale):</p>
            
            <table class="metrics-table">
                <thead>
                    <tr>
                        <th>Metric</th>
                        <th>Value</th>
                        <th>Interpretation</th>
                        <th>Status</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Mean Absolute Error (MAE)</strong></td>
                        <td>{{ results.regression_metrics.mae | round(2) }}</td>
                        <td>Average prediction error in points</td>
                        <td>
                            {% if results.regression_metrics.mae <= 10 %}
                            <span class="status-indicator status-good"></span><span class="good">Excellent</span>
                            {% elif results.regression_metrics.mae <= 20 %}
                            <span class="status-indicator status-warning"></span><span class="warning">Good</span>
                            {% else %}
                            <span class="status-indicator status-poor"></span><span class="poor">Needs Improvement</span>
                            {% endif %}
                        </td>
                    </tr>
                    <tr>
                        <td><strong>Root Mean Square Error (RMSE)</strong></td>
                        <td>{{ results.regression_metrics.rmse | round(2) }}</td>
                        <td>Penalizes larger errors more heavily</td>
                        <td>
                            {% if results.regression_metrics.rmse <= 15 %}
                            <span class="status-indicator status-good"></span><span class="good">Excellent</span>
                            {% elif results.regression_metrics.rmse <= 25 %}
                            <span class="status-indicator status-warning"></span><span class="warning">Good</span>
                            {% else %}
                            <span class="status-indicator status-poor"></span><span class="poor">Needs Improvement</span>
                            {% endif %}
                        </td>
                    </tr>
                    <tr>
                        <td><strong>R¬≤ Score</strong></td>
                        <td>{{ results.regression_metrics.r2 | round(3) }}</td>
                        <td>Proportion of variance explained</td>
                        <td>
                            {% if results.regression_metrics.r2 >= 0.8 %}
                            <span class="status-indicator status-good"></span><span class="good">Excellent</span>
                            {% elif results.regression_metrics.r2 >= 0.6 %}
                            <span class="status-indicator status-warning"></span><span class="warning">Good</span>
                            {% else %}
                            <span class="status-indicator status-poor"></span><span class="poor">Needs Improvement</span>
                            {% endif %}
                        </td>
                    </tr>
                    <tr>
                        <td><strong>Correlation</strong></td>
                        <td>{{ results.regression_metrics.correlation | round(3) }}</td>
                        <td>Linear relationship strength</td>
                        <td>
                            {% if results.regression_metrics.correlation >= 0.8 %}
                            <span class="status-indicator status-good"></span><span class="good">Strong</span>
                            {% elif results.regression_metrics.correlation >= 0.6 %}
                            <span class="status-indicator status-warning"></span><span class="warning">Moderate</span>
                            {% else %}
                            <span class="status-indicator status-poor"></span><span class="poor">Weak</span>
                            {% endif %}
                        </td>
                    </tr>
                    <tr>
                        <td><strong>Mean Abs Percentage Error (MAPE)</strong></td>
                        <td>{{ results.regression_metrics.mape | round(1) }}%</td>
                        <td>Average percentage error</td>
                        <td>
                            {% if results.regression_metrics.mape <= 15 %}
                            <span class="status-indicator status-good"></span><span class="good">Excellent</span>
                            {% elif results.regression_metrics.mape <= 25 %}
                            <span class="status-indicator status-warning"></span><span class="warning">Good</span>
                            {% else %}
                            <span class="status-indicator status-poor"></span><span class="poor">Needs Improvement</span>
                            {% endif %}
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
        {% endif %}

        {% if results.classification_metrics %}
        <!-- Classification Metrics Section -->
        <div class="section">
            <h2>üéØ Classification Metrics (Credit Classes)</h2>
            <p>Performance evaluation of credit class predictions (Poor, Average, Good):</p>
            
            <h3>Overall Performance</h3>
            <table class="metrics-table">
                <thead>
                    <tr>
                        <th>Metric</th>
                        <th>Value</th>
                        <th>Status</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Overall Accuracy</strong></td>
                        <td>{{ (results.classification_metrics.accuracy * 100) | round(1) }}%</td>
                        <td>
                            {% if results.classification_metrics.accuracy >= 0.8 %}
                            <span class="status-indicator status-good"></span><span class="good">Excellent</span>
                            {% elif results.classification_metrics.accuracy >= 0.6 %}
                            <span class="status-indicator status-warning"></span><span class="warning">Good</span>
                            {% else %}
                            <span class="status-indicator status-poor"></span><span class="poor">Needs Improvement</span>
                            {% endif %}
                        </td>
                    </tr>
                    <tr>
                        <td><strong>Macro F1-Score</strong></td>
                        <td>{{ (results.classification_metrics.macro_avg.f1_score * 100) | round(1) }}%</td>
                        <td>
                            {% if results.classification_metrics.macro_avg.f1_score >= 0.8 %}
                            <span class="status-indicator status-good"></span><span class="good">Excellent</span>
                            {% elif results.classification_metrics.macro_avg.f1_score >= 0.6 %}
                            <span class="status-indicator status-warning"></span><span class="warning">Good</span>
                            {% else %}
                            <span class="status-indicator status-poor"></span><span class="poor">Needs Improvement</span>
                            {% endif %}
                        </td>
                    </tr>
                    <tr>
                        <td><strong>Weighted F1-Score</strong></td>
                        <td>{{ (results.classification_metrics.weighted_avg.f1_score * 100) | round(1) }}%</td>
                        <td>
                            {% if results.classification_metrics.weighted_avg.f1_score >= 0.8 %}
                            <span class="status-indicator status-good"></span><span class="good">Excellent</span>
                            {% elif results.classification_metrics.weighted_avg.f1_score >= 0.6 %}
                            <span class="status-indicator status-warning"></span><span class="warning">Good</span>
                            {% else %}
                            <span class="status-indicator status-poor"></span><span class="poor">Needs Improvement</span>
                            {% endif %}
                        </td>
                    </tr>
                </tbody>
            </table>

            <h3>Class-Specific Performance</h3>
            <table class="metrics-table">
                <thead>
                    <tr>
                        <th>Class</th>
                        <th>Precision</th>
                        <th>Recall</th>
                        <th>F1-Score</th>
                        <th>Support</th>
                    </tr>
                </thead>
                <tbody>
                    {% for class_name, metrics in results.classification_metrics.class_metrics.items() %}
                    <tr>
                        <td><strong>{{ class_name }}</strong></td>
                        <td>{{ (metrics.precision * 100) | round(1) }}%</td>
                        <td>{{ (metrics.recall * 100) | round(1) }}%</td>
                        <td>{{ (metrics.f1_score * 100) | round(1) }}%</td>
                        <td>{{ metrics.support }}</td>
                    </tr>
                    {% endfor %}
                </tbody>
            </table>

            {% if results.classification_metrics.confusion_matrix %}
            <h3>Confusion Matrix</h3>
            <table class="metrics-table">
                <thead>
                    <tr>
                        <th>True \ Predicted</th>
                        <th>Poor</th>
                        <th>Average</th>
                        <th>Good</th>
                    </tr>
                </thead>
                <tbody>
                    {% for true_class, predictions in results.classification_metrics.confusion_matrix.items() %}
                    <tr>
                        <td><strong>{{ true_class }}</strong></td>
                        <td>{{ predictions.Poor }}</td>
                        <td>{{ predictions.Average }}</td>
                        <td>{{ predictions.Good }}</td>
                    </tr>
                    {% endfor %}
                </tbody>
            </table>
            {% endif %}
        </div>
        {% endif %}

        {% if results.distribution_analysis %}
        <!-- Distribution Analysis Section -->
        <div class="section">
            <h2>üìä Score Distribution Analysis</h2>
            <p>Comparison of predicted vs ground truth score distributions:</p>
            
            <h3>Statistical Summary</h3>
            <table class="metrics-table">
                <thead>
                    <tr>
                        <th>Statistic</th>
                        <th>Predicted Scores</th>
                        <th>Ground Truth</th>
                        <th>Difference</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Mean</strong></td>
                        <td>{{ results.distribution_analysis.predicted_stats.mean | round(1) }}</td>
                        <td>{{ results.distribution_analysis.true_stats.mean | round(1) }}</td>
                        <td>{{ (results.distribution_analysis.predicted_stats.mean - results.distribution_analysis.true_stats.mean) | round(1) }}</td>
                    </tr>
                    <tr>
                        <td><strong>Standard Deviation</strong></td>
                        <td>{{ results.distribution_analysis.predicted_stats.std | round(1) }}</td>
                        <td>{{ results.distribution_analysis.true_stats.std | round(1) }}</td>
                        <td>{{ (results.distribution_analysis.predicted_stats.std - results.distribution_analysis.true_stats.std) | round(1) }}</td>
                    </tr>
                    <tr>
                        <td><strong>Median</strong></td>
                        <td>{{ results.distribution_analysis.predicted_stats.median | round(1) }}</td>
                        <td>{{ results.distribution_analysis.true_stats.median | round(1) }}</td>
                        <td>{{ (results.distribution_analysis.predicted_stats.median - results.distribution_analysis.true_stats.median) | round(1) }}</td>
                    </tr>
                    <tr>
                        <td><strong>Min</strong></td>
                        <td>{{ results.distribution_analysis.predicted_stats.min | round(1) }}</td>
                        <td>{{ results.distribution_analysis.true_stats.min | round(1) }}</td>
                        <td>{{ (results.distribution_analysis.predicted_stats.min - results.distribution_analysis.true_stats.min) | round(1) }}</td>
                    </tr>
                    <tr>
                        <td><strong>Max</strong></td>
                        <td>{{ results.distribution_analysis.predicted_stats.max | round(1) }}</td>
                        <td>{{ results.distribution_analysis.true_stats.max | round(1) }}</td>
                        <td>{{ (results.distribution_analysis.predicted_stats.max - results.distribution_analysis.true_stats.max) | round(1) }}</td>
                    </tr>
                </tbody>
            </table>

            <h3>Range Distribution</h3>
            <div class="distribution-grid">
                {% for range_name, data in results.distribution_analysis.range_analysis.items() %}
                <div class="distribution-card">
                    <div class="range-label">{{ range_name }} Points</div>
                    <div class="range-values">
                        <div class="range-value">
                            <strong>Predicted:</strong><br>
                            {{ data.predicted_percentage | round(1) }}%<br>
                            ({{ data.predicted_count }} samples)
                        </div>
                        <div class="range-value">
                            <strong>Ground Truth:</strong><br>
                            {{ data.true_percentage | round(1) }}%<br>
                            ({{ data.true_count }} samples)
                        </div>
                    </div>
                </div>
                {% endfor %}
            </div>
        </div>
        {% endif %}

        <div class="section">
            <h2>üìã Analysis Summary</h2>
            <p><strong>Ground Truth Method:</strong> {{ results.ground_truth_method | default("Rule-based synthetic") }}</p>
            <p><strong>Total API Responses:</strong> {{ results.summary.total_responses }}</p>
            <p><strong>Valid Predictions:</strong> {{ results.summary.total_predictions }}</p>
            <p><strong>Success Rate:</strong> {{ (results.summary.valid_prediction_rate * 100) | round(1) }}%</p>
            
            {% if results.summary.valid_prediction_rate < 0.8 %}
            <div style="background: #fef3cd; border: 1px solid #fde68a; color: #92400e; padding: 15px; border-radius: 8px; margin-top: 15px;">
                <strong>‚ö†Ô∏è Low Success Rate Warning:</strong> 
                Only {{ (results.summary.valid_prediction_rate * 100) | round(1) }}% of API responses contained valid predictions. 
                Consider investigating API errors or response format issues.
            </div>
            {% endif %}
        </div>

        {% endif %}

        <div class="footer">
            <p>Credit Scoring Validator - Accuracy Analysis Report</p>
            <p>This report evaluates the accuracy of credit scoring predictions using rule-based ground truth for synthetic data validation.</p>
        </div>
    </div>
</body>
</html>
